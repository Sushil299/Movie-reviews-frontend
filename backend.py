# -*- coding: utf-8 -*-
"""backend

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TiA6-37RYxY1T4RB18XXJ009WhLO_oFm
"""

import os
import asyncpraw
import google.generativeai as genai
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from typing import Dict, Any
import logging
from datetime import datetime, timedelta
import json
import asyncio
from asyncio import sleep
import re

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Load API keys from environment variables
REDDIT_CLIENT_ID = os.getenv("REDDIT_CLIENT_ID")
REDDIT_CLIENT_SECRET = os.getenv("REDDIT_CLIENT_SECRET")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

# Initialize APIs
reddit = asyncpraw.Reddit(
    client_id=REDDIT_CLIENT_ID,
    client_secret=REDDIT_CLIENT_SECRET,
    user_agent="StockScraper"
)

genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel('gemini-1.5-flash')

INDIAN_MOVIE_SUBREDDITS = [
    "bollywood", "IndianCinema", "tollywood", "kollywood", "MalayalamMovies",
    "Lollywood", "BollyBlindsNGossip", "bollywoodmemes", "India", "AskIndia",
    "movies", "moviecritic", "shittymoviedetails", "netflix", "boxoffice"
]

# FastAPI App
app = FastAPI()

# Add CORS middleware to allow requests from any origin (important for frontend access)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Allows all origins
    allow_credentials=True,
    allow_methods=["*"],  # Allows all methods
    allow_headers=["*"],  # Allows all headers
)

# Function to repair and validate JSON
def repair_json(json_str):
    # Fix common JSON issues

    # Fix trailing commas in arrays (e.g., [1, 2, 3,])
    json_str = re.sub(r',\s*]', ']', json_str)

    # Fix trailing commas in objects (e.g., {"a": 1, "b": 2,})
    json_str = re.sub(r',\s*}', '}', json_str)

    # Fix missing quotes around property names
    json_str = re.sub(r'(\s*)(\w+)(\s*):', r'\1"\2"\3:', json_str)

    # Replace single quotes with double quotes
    json_str = json_str.replace("'", '"')

    # Ensure quotation marks around string values
    json_str = re.sub(r':\s*([^"\'\d\[\{][^,\}\]]*)', r': "\1"', json_str)

    # Try to fix malformed properties
    json_str = re.sub(r'"\s*:\s*"([^"]*)"([^,\}]*)', r'": "\1\2', json_str)

    # Clean up any double spaces in the JSON
    json_str = json_str.replace('  ', ' ')

    return json_str

@app.get("/")
async def home():
    return {"message": "Movie Review Backend is Running!"}

@app.get("/search_reddit")
async def search_reddit(movie_name: str, days: int = 60) -> Dict[str, Any]:
    comments, posts = [], []
    total_posts = 0
    time_threshold = datetime.utcnow() - timedelta(days=days)

    for subreddit_name in INDIAN_MOVIE_SUBREDDITS:
        try:
            # Add debug logging for authentication check
            logger.info(f"Searching subreddit: {subreddit_name} for movie: {movie_name}")

            # Create subreddit instance
            subreddit = await reddit.subreddit(subreddit_name)

            # Create search generator
            search_generator = subreddit.search(movie_name, time_filter="month", limit=10)

            # Collect search results into a list to verify we have data
            search_results = []
            async for result in search_generator:
                search_results.append(result)

            # Check if we found any results
            if not search_results:
                logger.info(f"No results found for {movie_name} in {subreddit_name}")
                continue

            # Process the results
            for post in search_results:
                post_time = datetime.fromtimestamp(post.created_utc)
                if post_time < time_threshold or post.score < 50:
                    continue

                total_posts += 1
                posts.append({
                    "title": post.title,
                    "score": post.score,
                    "url": f"https://www.reddit.com{post.permalink}",
                    "num_comments": post.num_comments
                })

                # Make sure to handle comments asynchronously
                try:
                    await post.comments.replace_more(limit=5)
                    # Get comment list ONLY if post.comments is not None
                    if post.comments is None:
                        logger.warning(f"No comments object for post in {subreddit_name}")
                        continue

                    # Safely get comments list - handle possible None cases
                    try:
                        comment_list = post.comments.list()
                        if comment_list is None:
                            logger.warning(f"Comment list is None for post in {subreddit_name}")
                            continue
                    except Exception as list_err:
                        logger.warning(f"Error getting comment list for post in {subreddit_name}: {str(list_err)}")
                        continue

                    # Now process comments safely
                    for comment in comment_list[:20]:
                        # Check if comment is valid and has required attributes
                        if (comment is not None and
                            hasattr(comment, 'body') and
                            hasattr(comment, 'score') and
                            hasattr(comment, 'author') and
                            hasattr(comment, 'permalink')):

                            if len(comment.body.strip()) > 30 and comment.score >= 20:
                                comments.append({
                                    "text": comment.body,
                                    "score": comment.score,
                                    "author": str(comment.author),
                                    "url": f"https://www.reddit.com{comment.permalink}"
                                })
                except Exception as comment_err:
                    logger.warning(f"Error processing comments for post in {subreddit_name}: {str(comment_err)}")
                    continue

        except Exception as e:
            logger.warning(f"Error searching subreddit {subreddit_name}: {str(e)}")
            # Add a delay between requests to avoid rate limiting
            await sleep(1)
            continue

        # Add a small delay between subreddit searches to avoid rate limiting
        await sleep(0.5)

    # Sort comments by score
    comments.sort(key=lambda x: x["score"], reverse=True)

    # Log the results for debugging
    logger.info(f"Found {len(posts)} posts and {len(comments)} comments for {movie_name}")

    return {"posts": posts, "comments": comments[:50], "total_posts": total_posts}

@app.get("/analyze")
async def analyze_with_gemini(movie_name: str) -> Dict[str, Any]:
    try:
        # Get Reddit data
        reddit_data = await search_reddit(movie_name, days=60)

        # Log the data for debugging
        logger.info(f"Reddit data for {movie_name}: {len(reddit_data['posts'])} posts, {len(reddit_data['comments'])} comments")

        # Check if we have enough data to analyze
        if not reddit_data["posts"] and not reddit_data["comments"]:
            logger.warning(f"Insufficient data found for movie: {movie_name}")
            return {
                "title": f"{movie_name} Analysis (Insufficient Data)",
                "analysis": {
                    "1. TL;DR Summary": f"There isn't enough online discussion available to form an analysis of {movie_name}.",
                    "2. Overall Sentiment Analysis": {
                        "positivePercentage": 0,
                        "negativePercentage": 0,
                        "neutralPercentage": 0,
                        "keyPhrases": [],
                        "confidenceLevel": "low"
                    },
                    "3. Summary of Audience Reactions": "Insufficient data to summarize audience reactions.",
                    "4. Key Aspects Discussed": {
                        "Acting": {"score": "N/A", "explanation": "Insufficient data"},
                        "Story": {"score": "N/A", "explanation": "Insufficient data"},
                        "Direction": {"score": "N/A", "explanation": "Insufficient data"},
                        "Music": {"score": "N/A", "explanation": "Insufficient data"},
                        "Cinematography": {"score": "N/A", "explanation": "Insufficient data"},
                        "Special Effects": {"score": "N/A", "explanation": "Insufficient data"}
                    },
                    "5. Common Praise & Complaints": {
                        "praise": [],
                        "complaints": []
                    },
                    "6. Comparison with Similar Movies": [],
                    "7. Final Verdict": {
                        "whoWouldEnjoy": "Insufficient data",
                        "whoMightNotEnjoy": "Insufficient data",
                        "theaterOrStreaming": "Insufficient data"
                    }
                }
            }

        # Prepare text for analysis
        posts_text = "\n\n".join([f"Post: {p['title']}" for p in reddit_data["posts"]])
        comments_text = "\n\n".join([f"Comment: {c['text']}" for c in reddit_data["comments"][:30]])

        # Create a much simpler prompt that focuses on getting valid JSON
        prompt = f"""
        Based on the Reddit discussions about the movie "{movie_name}", analyze the sentiment and key aspects.

        POSTS:
        {posts_text}

        COMMENTS:
        {comments_text}

        Create a JSON object with the following EXACT structure. Use double quotes for all strings and keys. Make sure the final output is valid JSON with NO trailing commas or other syntax errors:

        {{
          "title": "{movie_name} Movie Analysis Based on Reddit Discussions",
          "analysis": {{
            "1. TL;DR Summary": "Brief verdict on the movie",
            "2. Overall Sentiment Analysis": {{
              "positivePercentage": 35,
              "negativePercentage": 40,
              "neutralPercentage": 25,
              "keyPhrases": [
                "phrase1",
                "phrase2",
                "phrase3",
                "phrase4",
                "phrase5"
              ],
              "confidenceLevel": "medium"
            }},
            "3. Summary of Audience Reactions": "Overview of reactions",
            "4. Key Aspects Discussed": {{
              "Acting": {{
                "score": 8,
                "explanation": "Actor performance analysis"
              }},
              "Story": {{
                "score": 6,
                "explanation": "Story analysis"
              }},
              "Direction": {{
                "score": 7,
                "explanation": "Direction analysis"
              }},
              "Music": {{
                "score": 7,
                "explanation": "Music analysis"
              }},
              "Cinematography": {{
                "score": 7,
                "explanation": "Cinematography analysis"
              }},
              "Special Effects": {{
                "score": "N/A",
                "explanation": "Special effects analysis"
              }}
            }},
            "5. Common Praise & Complaints": {{
              "praise": [
                "praise1",
                "praise2",
                "praise3",
                "praise4",
                "praise5"
              ],
              "complaints": [
                "complaint1",
                "complaint2",
                "complaint3",
                "complaint4",
                "complaint5"
              ]
            }},
            "6. Comparison with Similar Movies": [
              {{
                "title": "Movie1",
                "year": 2017,
                "similarity": "Similarity explanation",
                "rating": "Rating comparison"
              }},
              {{
                "title": "Movie2",
                "year": 2019,
                "similarity": "Similarity explanation",
                "rating": "Rating comparison"
              }},
              {{
                "title": "Movie3",
                "year": 2021,
                "similarity": "Similarity explanation",
                "rating": "Rating comparison"
              }}
            ],
            "7. Final Verdict": {{
              "whoWouldEnjoy": "Who would enjoy",
              "whoMightNotEnjoy": "Who might not enjoy",
              "theaterOrStreaming": "Theater or streaming recommendation"
            }}
          }}
        }}

        Fill in the template with your analysis based on the Reddit data provided. Keep the structure EXACTLY as shown with no changes to the keys or format. The output must be a valid JSON object.
        """

        # Generate analysis with Gemini
        logger.info(f"Sending request to Gemini for movie: {movie_name}")
        generation_config = {
            "temperature": 0.1,  # Lower temperature for more predictable output
            "top_p": 0.95,
            "top_k": 40,
            "max_output_tokens": 4096,
        }

        safety_settings = [
            {
                "category": "HARM_CATEGORY_HARASSMENT",
                "threshold": "BLOCK_MEDIUM_AND_ABOVE"
            },
            {
                "category": "HARM_CATEGORY_HATE_SPEECH",
                "threshold": "BLOCK_MEDIUM_AND_ABOVE"
            },
            {
                "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                "threshold": "BLOCK_MEDIUM_AND_ABOVE"
            },
            {
                "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
                "threshold": "BLOCK_MEDIUM_AND_ABOVE"
            }
        ]

        response = model.generate_content(
            prompt,
            generation_config=generation_config,
            safety_settings=safety_settings
        )

        # Parse the response
        try:
            response_text = response.text

            # Log the raw response for debugging
            logger.info(f"Raw Gemini response first 200 chars: {response_text[:200]}...")

            # Extract JSON from response
            json_content = ""

            # Try different methods to extract the JSON
            if "```json" in response_text:
                json_content = response_text.split("```json")[1].split("```")[0].strip()
            elif "```" in response_text:
                json_content = response_text.split("```")[1].split("```")[0].strip()
            else:
                # Try to find a JSON object in the text
                start = response_text.find('{')
                end = response_text.rfind('}')
                if start != -1 and end != -1:
                    json_content = response_text[start:end+1].strip()
                else:
                    json_content = response_text.strip()

            # Repair the JSON before parsing
            repaired_json = repair_json(json_content)
            logger.info(f"Repaired JSON: {repaired_json[:200]}...")

            # Parse the JSON
            try:
                analysis_json = json.loads(repaired_json)
                return analysis_json
            except json.JSONDecodeError as json_err:
                logger.error(f"JSON decode error after repair: {str(json_err)}")
                logger.error(f"Attempted to parse: {repaired_json[:500]}...")

                # Try a more aggressive approach - use a JSON schema to create a new object
                # that matches the expected format
                hardcoded_template = {
                    "title": f"{movie_name} Movie Analysis Based on Reddit Discussions",
                    "analysis": {
                        "1. TL;DR Summary": "Unable to parse detailed analysis automatically, but the movie appears to have mixed reviews based on the Reddit data.",
                        "2. Overall Sentiment Analysis": {
                            "positivePercentage": 33,
                            "negativePercentage": 33,
                            "neutralPercentage": 34,
                            "keyPhrases": ["mixed reviews", "technical error", "parsing issue", "data available", "analysis needed"],
                            "confidenceLevel": "low"
                        },
                        "3. Summary of Audience Reactions": "Error parsing AI response. The raw response contains valuable information but had formatting issues.",
                        "4. Key Aspects Discussed": {
                            "Acting": {"score": 5, "explanation": "Mixed reviews mentioned in comments"},
                            "Story": {"score": 5, "explanation": "Mixed reviews mentioned in comments"},
                            "Direction": {"score": 5, "explanation": "Limited discussion in available data"},
                            "Music": {"score": 5, "explanation": "Limited discussion in available data"},
                            "Cinematography": {"score": 5, "explanation": "Limited discussion in available data"},
                            "Special Effects": {"score": "N/A", "explanation": "Not enough data available"}
                        },
                        "5. Common Praise & Complaints": {
                            "praise": ["Available in raw response", "Unable to extract automatically", "See comments for details", "", ""],
                            "complaints": ["Available in raw response", "Unable to extract automatically", "See comments for details", "", ""]
                        },
                        "6. Comparison with Similar Movies": [
                            {
                                "title": "Similar Movie",
                                "year": 2020,
                                "similarity": "Similar themes and audience",
                                "rating": "Not enough data to compare"
                            }
                        ],
                        "7. Final Verdict": {
                            "whoWouldEnjoy": "See raw Reddit comments for details",
                            "whoMightNotEnjoy": "See raw Reddit comments for details",
                            "theaterOrStreaming": "Check comments for context-specific recommendations"
                        }
                    }
                }

                # Extract some information from the text if possible to enhance the hardcoded template
                if "TL;DR" in response_text and ":" in response_text:
                    tldr_match = re.search(r'TL;DR[^"]*[":]([^"]*)', response_text)
                    if tldr_match:
                        hardcoded_template["analysis"]["1. TL;DR Summary"] = tldr_match.group(1).strip()

                return hardcoded_template

        except Exception as parse_err:
            logger.error(f"Error parsing Gemini response: {str(parse_err)}")
            logger.error(f"Raw response: {response_text[:500]}...")  # Log first 500 chars

            # Return a fallback response
            return {
                "title": f"{movie_name} Analysis (Error)",
                "analysis": {
                    "1. TL;DR Summary": f"Unable to generate a proper analysis for {movie_name} due to technical issues.",
                    "2. Overall Sentiment Analysis": {
                        "positivePercentage": 0,
                        "negativePercentage": 0,
                        "neutralPercentage": 0,
                        "keyPhrases": [],
                        "confidenceLevel": "low"
                    },
                    "3. Summary of Audience Reactions": "Error processing AI response.",
                    "4. Key Aspects Discussed": {
                        "Acting": {"score": "N/A", "explanation": "Error processing response"},
                        "Story": {"score": "N/A", "explanation": "Error processing response"},
                        "Direction": {"score": "N/A", "explanation": "Error processing response"},
                        "Music": {"score": "N/A", "explanation": "Error processing response"},
                        "Cinematography": {"score": "N/A", "explanation": "Error processing response"},
                        "Special Effects": {"score": "N/A", "explanation": "Error processing response"}
                    },
                    "5. Common Praise & Complaints": {
                        "praise": [],
                        "complaints": []
                    },
                    "6. Comparison with Similar Movies": [],
                    "7. Final Verdict": {
                        "whoWouldEnjoy": "Error processing response",
                        "whoMightNotEnjoy": "Error processing response",
                        "theaterOrStreaming": "Error processing response"
                    }
                }
            }

    except Exception as e:
        logger.error(f"Error in analyze_with_gemini: {str(e)}")
        return {
            "title": f"{movie_name} Analysis (General Error)",
            "analysis": {
                "1. TL;DR Summary": f"An error occurred while analyzing {movie_name}.",
                "2. Overall Sentiment Analysis": {
                    "positivePercentage": 0,
                    "negativePercentage": 0,
                    "neutralPercentage": 0,
                    "keyPhrases": [],
                    "confidenceLevel": "low"
                },
                "3. Summary of Audience Reactions": f"Error: {str(e)}",
                "4. Key Aspects Discussed": {
                    "Acting": {"score": "N/A", "explanation": "Error occurred"},
                    "Story": {"score": "N/A", "explanation": "Error occurred"},
                    "Direction": {"score": "N/A", "explanation": "Error occurred"},
                    "Music": {"score": "N/A", "explanation": "Error occurred"},
                    "Cinematography": {"score": "N/A", "explanation": "Error occurred"},
                    "Special Effects": {"score": "N/A", "explanation": "Error occurred"}
                },
                "5. Common Praise & Complaints": {
                    "praise": [],
                    "complaints": []
                },
                "6. Comparison with Similar Movies": [],
                "7. Final Verdict": {
                    "whoWouldEnjoy": "Error occurred",
                    "whoMightNotEnjoy": "Error occurred",
                    "theaterOrStreaming": "Error occurred"
                }
            }
        }

# Run the app using `uvicorn backend:app --host 0.0.0.0 --port 8000`